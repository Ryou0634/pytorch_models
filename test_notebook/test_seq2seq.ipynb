{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_utils import Dictionary\n",
    "\n",
    "n_unique = 10\n",
    "\n",
    "src_dict = Dictionary(['<EOS>'])\n",
    "tgt_dict = Dictionary(['<BOS>', '<EOS>'])\n",
    "for n in range(n_unique):\n",
    "    src_dict.add_word(str(n))\n",
    "    tgt_dict.add_word(str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_utils.toy_data import invert_seq\n",
    "train = invert_seq(5000, n_unique=n_unique)\n",
    "test = invert_seq(100, n_unique=n_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader(\n",
      "\tdatasize: 5000\n",
      "\tbatchsize: 3\n",
      "\tn_batches: 1667\n",
      "\ttrans_func: seq2seq\n",
      "\tdevice: cpu\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from my_utils import DataLoader\n",
    "from torch_models.utils import seq2seq\n",
    "\n",
    "def numericalize(dataset, src_dict, tgt_dict):\n",
    "    numericalized = [([src_dict(s) for s in src], [tgt_dict(t) for t in tgt]) for src, tgt in dataset]\n",
    "    return numericalized\n",
    "\n",
    "# device = 'cuda:0'\n",
    "device = torch.device('cpu')\n",
    "trans_func = seq2seq(device)\n",
    "\n",
    "train_loader = DataLoader(numericalize(train, src_dict, tgt_dict), batch_size=3, trans_func=trans_func)\n",
    "test_loader = DataLoader(numericalize(test, src_dict, tgt_dict), batch_size=50, trans_func=trans_func)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttnSeq2Seq(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embedding): Embedding(12, 64, padding_idx=11)\n",
      "    (rnn): LSTM(64, 64, num_layers=2, bidirectional=True)\n",
      "  )\n",
      "  (decoder): RNNEncoder(\n",
      "    (embedding): Embedding(13, 64, padding_idx=12)\n",
      "    (rnn): LSTM(128, 64, num_layers=2)\n",
      "  )\n",
      "  (generator): MLP(\n",
      "    (fc_out): Linear(in_features=64, out_features=12, bias=True)\n",
      "    (dropout): Dropout(p=0)\n",
      "    (criterion): CrossEntropyLoss()\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (attention): BiLinearAttn(\n",
      "    (linear): Linear(in_features=64, out_features=64, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_models import AttnSeq2Seq, Seq2Seq\n",
    "\n",
    "embed_size=64\n",
    "dropout=0\n",
    "model = AttnSeq2Seq(embed_size=embed_size, hidden_size=embed_size, src_vocab_size=len(src_dict), tgt_vocab_size=len(tgt_dict),\n",
    "                    src_EOS=src_dict('<EOS>'), tgt_BOS=tgt_dict('<BOS>'), tgt_EOS=tgt_dict('<EOS>'),\n",
    "                    num_layers=2, bidirectional=True, dropout=dropout, rnn='LSTM',\n",
    "                    attention='bilinear', fuse_query='add', input_feeding=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0435,  0.0482,  0.1312,  0.1326,  0.1308,  0.0004,  0.0260,\n",
       "         -0.0086,  0.0914,  0.0520, -0.0205,  0.2289,  0.0085,  0.1192,\n",
       "         -0.0428,  0.1020,  0.1002, -0.0133, -0.0635, -0.1770, -0.0924,\n",
       "         -0.1275, -0.0476,  0.0240, -0.1513, -0.0148, -0.1380,  0.1871,\n",
       "          0.0782, -0.0613,  0.0673, -0.0782, -0.0476,  0.0240, -0.0239,\n",
       "          0.1622, -0.0246, -0.0250, -0.0239, -0.0447, -0.0939,  0.1039,\n",
       "         -0.0374, -0.0226, -0.0015,  0.1455, -0.0287,  0.0617,  0.1312,\n",
       "         -0.0151,  0.1560,  0.0158,  0.0607,  0.0279, -0.0392, -0.0542,\n",
       "         -0.1133, -0.0898, -0.0582,  0.0746,  0.0428,  0.0838, -0.0336,\n",
       "          0.0275],\n",
       "        [-0.0180,  0.0337,  0.1198,  0.1294,  0.0881,  0.0095,  0.0109,\n",
       "         -0.0351,  0.0690,  0.0355, -0.0142,  0.2128,  0.0356,  0.1107,\n",
       "         -0.0376,  0.0726,  0.0653, -0.0207, -0.0436, -0.1445, -0.0812,\n",
       "         -0.1157, -0.0591,  0.0130, -0.1331,  0.0094, -0.1223,  0.1424,\n",
       "          0.0724, -0.0550,  0.0942, -0.0768, -0.0306,  0.0477,  0.0009,\n",
       "          0.1068, -0.0392, -0.0106, -0.0339, -0.0280, -0.0738,  0.0671,\n",
       "         -0.0178, -0.0071,  0.0053,  0.1467, -0.0429,  0.0376,  0.0998,\n",
       "          0.0168,  0.1464,  0.0282,  0.0471,  0.0230, -0.0426, -0.0692,\n",
       "         -0.1102, -0.0481, -0.0405,  0.0675,  0.0271,  0.0958, -0.0294,\n",
       "          0.0444],\n",
       "        [-0.0108,  0.0244,  0.1167,  0.1230,  0.0650,  0.0066, -0.0015,\n",
       "         -0.0442,  0.0532,  0.0319, -0.0093,  0.2065,  0.0495,  0.1021,\n",
       "         -0.0326,  0.0607,  0.0483, -0.0240, -0.0368, -0.1290, -0.0774,\n",
       "         -0.1080, -0.0652,  0.0034, -0.1290,  0.0230, -0.1144,  0.1201,\n",
       "          0.0691, -0.0509,  0.1114, -0.0715, -0.0234,  0.0586,  0.0145,\n",
       "          0.0760, -0.0476,  0.0015, -0.0372, -0.0193, -0.0612,  0.0519,\n",
       "         -0.0047,  0.0050,  0.0143,  0.1454, -0.0440,  0.0290,  0.0859,\n",
       "          0.0370,  0.1496,  0.0381,  0.0405,  0.0196, -0.0445, -0.0735,\n",
       "         -0.1086, -0.0292, -0.0310,  0.0616,  0.0215,  0.1041, -0.0263,\n",
       "          0.0525],\n",
       "        [-0.0459,  0.0530,  0.1348,  0.1414,  0.1425, -0.0027,  0.0333,\n",
       "          0.0018,  0.0953,  0.0617, -0.0281,  0.2346,  0.0050,  0.1323,\n",
       "         -0.0538,  0.1226,  0.1153, -0.0148, -0.0655, -0.1923, -0.1003,\n",
       "         -0.1278, -0.0394,  0.0307, -0.1667, -0.0143, -0.1420,  0.2086,\n",
       "          0.0971, -0.0731,  0.0702, -0.0853, -0.0584,  0.0188, -0.0356,\n",
       "          0.1852, -0.0263, -0.0336, -0.0203, -0.0445, -0.1020,  0.1158,\n",
       "         -0.0453, -0.0300, -0.0045,  0.1528, -0.0270,  0.0783,  0.1435,\n",
       "         -0.0132,  0.1651,  0.0249,  0.0653,  0.0316, -0.0437, -0.0533,\n",
       "         -0.1122, -0.1055, -0.0690,  0.0836,  0.0448,  0.0872, -0.0308,\n",
       "          0.0233],\n",
       "        [-0.0196,  0.0384,  0.1247,  0.1371,  0.0978,  0.0074,  0.0169,\n",
       "         -0.0269,  0.0727,  0.0438, -0.0194,  0.2175,  0.0319,  0.1217,\n",
       "         -0.0465,  0.0890,  0.0786, -0.0221, -0.0457, -0.1579, -0.0877,\n",
       "         -0.1169, -0.0519,  0.0190, -0.1473,  0.0103, -0.1257,  0.1610,\n",
       "          0.0875, -0.0653,  0.0965, -0.0831, -0.0411,  0.0440, -0.0087,\n",
       "          0.1264, -0.0401, -0.0171, -0.0319, -0.0290, -0.0813,  0.0774,\n",
       "         -0.0242, -0.0150,  0.0020,  0.1542, -0.0415,  0.0517,  0.1106,\n",
       "          0.0187,  0.1541,  0.0350,  0.0520,  0.0256, -0.0465, -0.0691,\n",
       "         -0.1091, -0.0615, -0.0502,  0.0754,  0.0287,  0.0984, -0.0281,\n",
       "          0.0408],\n",
       "        [-0.0132,  0.0290,  0.1205,  0.1316,  0.0737,  0.0042,  0.0037,\n",
       "         -0.0385,  0.0579,  0.0397, -0.0128,  0.2101,  0.0456,  0.1113,\n",
       "         -0.0401,  0.0749,  0.0627, -0.0267, -0.0390, -0.1396, -0.0829,\n",
       "         -0.1098, -0.0573,  0.0079, -0.1440,  0.0233, -0.1175,  0.1374,\n",
       "          0.0836, -0.0598,  0.1130, -0.0792, -0.0321,  0.0534,  0.0045,\n",
       "          0.0933, -0.0467, -0.0047, -0.0372, -0.0187, -0.0661,  0.0616,\n",
       "         -0.0095, -0.0031,  0.0128,  0.1524, -0.0434,  0.0410,  0.0949,\n",
       "          0.0403,  0.1564,  0.0450,  0.0435,  0.0242, -0.0469, -0.0741,\n",
       "         -0.1077, -0.0429, -0.0399,  0.0702,  0.0225,  0.1073, -0.0263,\n",
       "          0.0501],\n",
       "        [-0.0149,  0.0230,  0.1189,  0.1261,  0.0620,  0.0001, -0.0053,\n",
       "         -0.0410,  0.0482,  0.0406, -0.0082,  0.2087,  0.0524,  0.1042,\n",
       "         -0.0362,  0.0684,  0.0537, -0.0283, -0.0353, -0.1321, -0.0806,\n",
       "         -0.1042, -0.0597, -0.0007, -0.1450,  0.0300, -0.1123,  0.1274,\n",
       "          0.0818, -0.0578,  0.1236, -0.0738, -0.0299,  0.0590,  0.0128,\n",
       "          0.0762, -0.0508,  0.0037, -0.0389, -0.0134, -0.0588,  0.0560,\n",
       "         -0.0009,  0.0046,  0.0218,  0.1513, -0.0413,  0.0373,  0.0889,\n",
       "          0.0519,  0.1612,  0.0516,  0.0404,  0.0211, -0.0465, -0.0741,\n",
       "         -0.1055, -0.0326, -0.0347,  0.0661,  0.0204,  0.1118, -0.0251,\n",
       "          0.0549],\n",
       "        [-0.0178,  0.0199,  0.1168,  0.1226,  0.0561, -0.0034, -0.0107,\n",
       "         -0.0431,  0.0426,  0.0421, -0.0055,  0.2081,  0.0560,  0.0997,\n",
       "         -0.0333,  0.0662,  0.0521, -0.0285, -0.0343, -0.1271, -0.0808,\n",
       "         -0.1012, -0.0615, -0.0067, -0.1467,  0.0333, -0.1110,  0.1233,\n",
       "          0.0821, -0.0554,  0.1306, -0.0718, -0.0280,  0.0604,  0.0161,\n",
       "          0.0665, -0.0524,  0.0077, -0.0403, -0.0091, -0.0528,  0.0524,\n",
       "          0.0049,  0.0094,  0.0286,  0.1497, -0.0393,  0.0353,  0.0849,\n",
       "          0.0582,  0.1638,  0.0579,  0.0383,  0.0220, -0.0461, -0.0732,\n",
       "         -0.1043, -0.0285, -0.0311,  0.0644,  0.0197,  0.1159, -0.0230,\n",
       "          0.0568],\n",
       "        [-0.0427,  0.0522,  0.1341,  0.1390,  0.1370, -0.0008,  0.0272,\n",
       "         -0.0045,  0.0912,  0.0595, -0.0241,  0.2285,  0.0089,  0.1256,\n",
       "         -0.0534,  0.1077,  0.1139, -0.0206, -0.0646, -0.1910, -0.1036,\n",
       "         -0.1380, -0.0439,  0.0231, -0.1587, -0.0256, -0.1376,  0.1995,\n",
       "          0.0864, -0.0746,  0.0726, -0.0771, -0.0541,  0.0156, -0.0390,\n",
       "          0.1727, -0.0238, -0.0276, -0.0232, -0.0491, -0.0992,  0.1159,\n",
       "         -0.0368, -0.0290, -0.0088,  0.1493, -0.0310,  0.0647,  0.1384,\n",
       "         -0.0126,  0.1669,  0.0281,  0.0625,  0.0243, -0.0428, -0.0667,\n",
       "         -0.1138, -0.0939, -0.0608,  0.0832,  0.0419,  0.0870, -0.0385,\n",
       "          0.0279],\n",
       "        [-0.0166,  0.0368,  0.1225,  0.1343,  0.0923,  0.0079,  0.0112,\n",
       "         -0.0317,  0.0707,  0.0410, -0.0166,  0.2122,  0.0361,  0.1152,\n",
       "         -0.0460,  0.0773,  0.0782, -0.0251, -0.0463, -0.1555, -0.0905,\n",
       "         -0.1255, -0.0575,  0.0108, -0.1407, -0.0004, -0.1239,  0.1532,\n",
       "          0.0789, -0.0657,  0.0990, -0.0780, -0.0353,  0.0398, -0.0136,\n",
       "          0.1140, -0.0379, -0.0136, -0.0331, -0.0317, -0.0766,  0.0767,\n",
       "         -0.0177, -0.0144, -0.0022,  0.1505, -0.0433,  0.0413,  0.1047,\n",
       "          0.0177,  0.1539,  0.0400,  0.0494,  0.0213, -0.0466, -0.0802,\n",
       "         -0.1102, -0.0525, -0.0433,  0.0743,  0.0261,  0.1004, -0.0326,\n",
       "          0.0446],\n",
       "        [-0.0118,  0.0269,  0.1190,  0.1290,  0.0692,  0.0049, -0.0014,\n",
       "         -0.0418,  0.0553,  0.0378, -0.0111,  0.2042,  0.0498,  0.1054,\n",
       "         -0.0395,  0.0645,  0.0599, -0.0281, -0.0398, -0.1384, -0.0858,\n",
       "         -0.1164, -0.0634,  0.0004, -0.1365,  0.0152, -0.1154,  0.1299,\n",
       "          0.0755, -0.0603,  0.1146, -0.0741, -0.0288,  0.0499,  0.0013,\n",
       "          0.0809, -0.0454, -0.0021, -0.0366, -0.0220, -0.0621,  0.0606,\n",
       "         -0.0040, -0.0033,  0.0085,  0.1484, -0.0448,  0.0317,  0.0914,\n",
       "          0.0394,  0.1577,  0.0506,  0.0411,  0.0178, -0.0475, -0.0834,\n",
       "         -0.1089, -0.0337, -0.0343,  0.0671,  0.0207,  0.1075, -0.0286,\n",
       "          0.0512],\n",
       "        [-0.0145,  0.0209,  0.1182,  0.1245,  0.0573,  0.0004, -0.0088,\n",
       "         -0.0460,  0.0470,  0.0394, -0.0058,  0.2033,  0.0572,  0.1003,\n",
       "         -0.0352,  0.0587,  0.0521, -0.0310, -0.0360, -0.1306, -0.0847,\n",
       "         -0.1108, -0.0665, -0.0061, -0.1378,  0.0227, -0.1118,  0.1193,\n",
       "          0.0758, -0.0582,  0.1250, -0.0697, -0.0260,  0.0540,  0.0103,\n",
       "          0.0643, -0.0494,  0.0043, -0.0387, -0.0168, -0.0554,  0.0540,\n",
       "          0.0056,  0.0057,  0.0177,  0.1466, -0.0410,  0.0268,  0.0849,\n",
       "          0.0510,  0.1605,  0.0570,  0.0369,  0.0153, -0.0460, -0.0832,\n",
       "         -0.1064, -0.0232, -0.0285,  0.0627,  0.0183,  0.1126, -0.0278,\n",
       "          0.0553]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader)\n",
    "inputs, targets = next(train_loader)\n",
    "\n",
    "encoded = model.encode(inputs)\n",
    "model.decode_input_feeding(targets, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 114 ms, total: 16.9 s\n",
      "Wall time: 8.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for inputs, targets in train_loader:\n",
    "    encoded = model.encode(inputs)\n",
    "    decoded_ = model.decode_input_feeding(targets, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 85.5 ms, total: 13.5 s\n",
      "Wall time: 6.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for inputs, targets in train_loader:\n",
    "    encoded = model.encode(inputs)\n",
    "    decoded = model.decode(targets, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.76 s, sys: 50.5 ms, total: 7.81 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    for inputs, targets in train_loader:\n",
    "        decoded = model.decode(inputs, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-27 02:13:24,574 INFO] steps [100/100]\tloss: 1.9606751823425292\t\n",
      "[2018-10-27 02:13:24,640 INFO] Evaluator accuracy: 0.671875\t\n",
      "[2018-10-27 02:13:27,495 INFO] steps [100/100]\tloss: 0.33240895237773654\t\n",
      "[2018-10-27 02:13:27,561 INFO] Evaluator accuracy: 1.0\t\n",
      "[2018-10-27 02:13:30,236 INFO] steps [100/100]\tloss: 0.03726597668603063\t\n",
      "[2018-10-27 02:13:30,297 INFO] Evaluator accuracy: 1.0\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.1 s, sys: 332 ms, total: 23.4 s\n",
      "Wall time: 8.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from my_utils import Trainer, EvaluatorSeq, EvaluatorLoss\n",
    "from my_utils.misc.logging import init_logger\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "init_logger()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "evaluator = EvaluatorSeq(model, test_loader, measure='accuracy')\n",
    "# evaluator = EvaluatorLoss(model, test_loader)\n",
    "\n",
    "trainer = Trainer(model, train_loader)\n",
    "trainer.train_epoch(optimizer, max_epoch=3,\n",
    "              evaluator=evaluator, score_monitor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter(test_loader)\n",
    "inputs, targets = next(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.4424, -0.1017,  1.5236, -1.4988,  1.3046, -1.0514,  1.2535,\n",
      "          -0.0197,  1.1458, -1.2257, -0.0167,  0.9817,  1.2132,  0.2181,\n",
      "          -1.4476, -1.3340, -1.3247,  1.3937, -1.2628,  1.1180,  1.1383,\n",
      "          -1.2805, -1.0017,  1.4529, -0.1208,  1.2628, -0.1153,  0.8560,\n",
      "           1.3472, -1.3998,  1.2472, -1.5000,  1.1410,  0.8864, -0.3519,\n",
      "          -1.2725,  1.2763,  1.2862,  1.4910,  0.3846, -0.2490,  1.4636,\n",
      "          -1.3695,  1.3621,  1.1179, -0.2767, -1.4731, -1.3272, -1.2645,\n",
      "          -0.8719, -0.6327,  0.1412, -1.2650, -1.4987, -1.3373, -1.5591,\n",
      "           1.2529, -1.2680, -1.0812,  1.3748, -0.1330, -1.4495, -1.2359,\n",
      "           0.9917]]])\n",
      "tensor([[[ 1.4424, -0.1017,  1.5236, -1.4988,  1.3046, -1.0514,  1.2535,\n",
      "          -0.0197,  1.1458, -1.2257, -0.0167,  0.9817,  1.2132,  0.2181,\n",
      "          -1.4476, -1.3340, -1.3247,  1.3937, -1.2628,  1.1180,  1.1383,\n",
      "          -1.2805, -1.0017,  1.4529, -0.1208,  1.2628, -0.1153,  0.8560,\n",
      "           1.3472, -1.3998,  1.2472, -1.5000,  1.1410,  0.8864, -0.3519,\n",
      "          -1.2725,  1.2763,  1.2862,  1.4910,  0.3846, -0.2490,  1.4636,\n",
      "          -1.3695,  1.3621,  1.1179, -0.2767, -1.4731, -1.3272, -1.2645,\n",
      "          -0.8719, -0.6327,  0.1412, -1.2650, -1.4987, -1.3373, -1.5591,\n",
      "           1.2529, -1.2680, -1.0812,  1.3748, -0.1330, -1.4495, -1.2359,\n",
      "           0.9917]]])\n",
      "tensor([[[-0.4486, -1.4573, -0.0269, -1.4397,  1.6986, -0.0081,  0.0179,\n",
      "          -1.3928,  1.7267, -1.6974, -1.4888, -0.4296,  1.6948,  1.4529,\n",
      "           0.3036, -0.2611, -0.5812,  1.3053, -0.0397, -0.3128,  0.0634,\n",
      "          -0.5995, -1.3821,  1.0477, -1.4751,  1.6961, -1.4587, -1.0125,\n",
      "           1.3905,  0.1463,  1.7107, -1.6499,  0.8127,  1.6155,  0.5871,\n",
      "          -1.6931,  1.5407,  1.5300,  0.0335,  1.4797, -1.3609,  1.0015,\n",
      "          -1.7134,  1.6117,  1.7020, -1.4665, -1.1270, -0.9243, -1.7337,\n",
      "           0.3427,  1.2784, -0.0234,  0.1879, -0.8951,  0.3421, -0.4502,\n",
      "          -0.2738, -1.7117,  0.1367,  0.1208, -1.4336, -1.7369,  0.0685,\n",
      "           1.6702]]])\n",
      "tensor([[[-0.4486, -1.4573, -0.0269, -1.4397,  1.6986, -0.0081,  0.0179,\n",
      "          -1.3928,  1.7267, -1.6974, -1.4888, -0.4296,  1.6948,  1.4529,\n",
      "           0.3036, -0.2611, -0.5812,  1.3053, -0.0397, -0.3128,  0.0634,\n",
      "          -0.5995, -1.3821,  1.0477, -1.4751,  1.6961, -1.4587, -1.0125,\n",
      "           1.3905,  0.1463,  1.7107, -1.6499,  0.8127,  1.6155,  0.5871,\n",
      "          -1.6931,  1.5407,  1.5300,  0.0335,  1.4797, -1.3609,  1.0015,\n",
      "          -1.7134,  1.6117,  1.7020, -1.4665, -1.1270, -0.9243, -1.7337,\n",
      "           0.3427,  1.2784, -0.0234,  0.1879, -0.8951,  0.3421, -0.4502,\n",
      "          -0.2738, -1.7117,  0.1367,  0.1208, -1.4336, -1.7369,  0.0685,\n",
      "           1.6702]]])\n",
      "tensor([[[-0.4485, -1.4573, -0.0269, -1.4397,  1.6986, -0.0081,  0.0179,\n",
      "          -1.3927,  1.7266, -1.6974, -1.4887, -0.4295,  1.6948,  1.4528,\n",
      "           0.3036, -0.2612, -0.5813,  1.3053, -0.0398, -0.3127,  0.0635,\n",
      "          -0.5996, -1.3821,  1.0477, -1.4751,  1.6961, -1.4586, -1.0124,\n",
      "           1.3905,  0.1462,  1.7107, -1.6499,  0.8127,  1.6154,  0.5871,\n",
      "          -1.6930,  1.5407,  1.5299,  0.0335,  1.4797, -1.3609,  1.0015,\n",
      "          -1.7134,  1.6117,  1.7019, -1.4664, -1.1271, -0.9243, -1.7337,\n",
      "           0.3426,  1.2783, -0.0234,  0.1879, -0.8951,  0.3421, -0.4502,\n",
      "          -0.2737, -1.7116,  0.1366,  0.1209, -1.4335, -1.7369,  0.0684,\n",
      "           1.6702]]])\n",
      "tensor([[[-0.4485, -1.4573, -0.0269, -1.4397,  1.6986, -0.0081,  0.0179,\n",
      "          -1.3927,  1.7266, -1.6974, -1.4887, -0.4295,  1.6948,  1.4528,\n",
      "           0.3036, -0.2612, -0.5813,  1.3053, -0.0398, -0.3127,  0.0635,\n",
      "          -0.5996, -1.3821,  1.0477, -1.4751,  1.6961, -1.4586, -1.0124,\n",
      "           1.3905,  0.1462,  1.7107, -1.6499,  0.8127,  1.6154,  0.5871,\n",
      "          -1.6930,  1.5407,  1.5299,  0.0335,  1.4797, -1.3609,  1.0015,\n",
      "          -1.7134,  1.6117,  1.7019, -1.4664, -1.1271, -0.9243, -1.7337,\n",
      "           0.3426,  1.2783, -0.0234,  0.1879, -0.8951,  0.3421, -0.4502,\n",
      "          -0.2737, -1.7116,  0.1366,  0.1209, -1.4335, -1.7369,  0.0684,\n",
      "           1.6702]]])\n",
      "tensor([[[ 1.4424, -0.1017,  1.5236, -1.4988,  1.3046, -1.0514,  1.2536,\n",
      "          -0.0197,  1.1458, -1.2257, -0.0167,  0.9817,  1.2132,  0.2181,\n",
      "          -1.4476, -1.3340, -1.3247,  1.3937, -1.2628,  1.1180,  1.1383,\n",
      "          -1.2805, -1.0017,  1.4529, -0.1208,  1.2628, -0.1153,  0.8560,\n",
      "           1.3472, -1.3998,  1.2472, -1.5000,  1.1410,  0.8864, -0.3519,\n",
      "          -1.2725,  1.2763,  1.2862,  1.4910,  0.3846, -0.2490,  1.4636,\n",
      "          -1.3695,  1.3621,  1.1179, -0.2767, -1.4731, -1.3272, -1.2645,\n",
      "          -0.8719, -0.6327,  0.1412, -1.2650, -1.4987, -1.3373, -1.5591,\n",
      "           1.2529, -1.2680, -1.0812,  1.3748, -0.1330, -1.4495, -1.2359,\n",
      "           0.9917]]])\n",
      "tensor([[[ 1.4424, -0.1017,  1.5236, -1.4988,  1.3046, -1.0514,  1.2536,\n",
      "          -0.0197,  1.1458, -1.2257, -0.0167,  0.9817,  1.2132,  0.2181,\n",
      "          -1.4476, -1.3340, -1.3247,  1.3937, -1.2628,  1.1180,  1.1383,\n",
      "          -1.2805, -1.0017,  1.4529, -0.1208,  1.2628, -0.1153,  0.8560,\n",
      "           1.3472, -1.3998,  1.2472, -1.5000,  1.1410,  0.8864, -0.3519,\n",
      "          -1.2725,  1.2763,  1.2862,  1.4910,  0.3846, -0.2490,  1.4636,\n",
      "          -1.3695,  1.3621,  1.1179, -0.2767, -1.4731, -1.3272, -1.2645,\n",
      "          -0.8719, -0.6327,  0.1412, -1.2650, -1.4987, -1.3373, -1.5591,\n",
      "           1.2529, -1.2680, -1.0812,  1.3748, -0.1330, -1.4495, -1.2359,\n",
      "           0.9917]]])\n",
      "tensor([[[-1.0256, -1.0254, -0.9676,  0.3485, -0.8904,  1.0626,  1.0998,\n",
      "          -1.1003,  0.0944, -0.0825, -1.1228, -1.0566, -0.2543,  1.1880,\n",
      "           1.2535, -1.0621, -1.0644, -0.0418, -1.0986, -1.1610,  1.0886,\n",
      "          -1.1396,  1.0950,  0.0029, -1.1075, -0.8424, -1.1128,  1.1134,\n",
      "           0.1106,  1.0437,  0.1061,  0.1035, -1.0507, -0.2161, -1.1107,\n",
      "          -0.8136, -0.0092, -0.0668, -0.3342,  1.0862, -1.1523,  0.0146,\n",
      "           0.2603, -0.1243,  0.9248, -1.0824,  1.0953, -0.0789, -0.1549,\n",
      "          -1.1378,  1.4655,  1.1011, -1.1598,  0.0268, -1.0879,  0.8955,\n",
      "           1.2001, -0.0642, -1.1412,  1.0223, -1.1154,  0.0078, -1.0804,\n",
      "           0.0589]]])\n",
      "tensor([[[-1.0256, -1.0254, -0.9676,  0.3485, -0.8904,  1.0626,  1.0998,\n",
      "          -1.1003,  0.0944, -0.0825, -1.1228, -1.0566, -0.2543,  1.1880,\n",
      "           1.2535, -1.0621, -1.0644, -0.0418, -1.0986, -1.1610,  1.0886,\n",
      "          -1.1396,  1.0950,  0.0029, -1.1075, -0.8424, -1.1128,  1.1134,\n",
      "           0.1106,  1.0437,  0.1061,  0.1035, -1.0507, -0.2161, -1.1107,\n",
      "          -0.8136, -0.0092, -0.0668, -0.3342,  1.0862, -1.1523,  0.0146,\n",
      "           0.2603, -0.1243,  0.9248, -1.0824,  1.0953, -0.0789, -0.1549,\n",
      "          -1.1378,  1.4655,  1.1011, -1.1598,  0.0268, -1.0879,  0.8955,\n",
      "           1.2001, -0.0642, -1.1412,  1.0223, -1.1154,  0.0078, -1.0804,\n",
      "           0.0589]]])\n",
      "======= input ======\n",
      "['9', '0', '1', '1', '0']\n",
      "======= output ======\n",
      "['0', '1', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "iter(train_loader)\n",
    "l = 10\n",
    "inputs, targets = next(train_loader)\n",
    "inputs = inputs[:l]\n",
    "targets = targets[:l]\n",
    "generated = model.predict(inputs)\n",
    "print('======= input ======')\n",
    "for seq in inputs:\n",
    "    print([src_dict[s.item()] for s in seq])\n",
    "print('======= output ======')\n",
    "for seq in generated[:l]:\n",
    "    print([tgt_dict[s] for s in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
